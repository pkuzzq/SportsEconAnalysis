<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>体育经济分析：理论与应用</title>
    <meta charset="utf-8" />
    <meta name="author" content="周正卿" />
    <meta name="date" content="2022-03-02" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# 体育经济分析：理论与应用
## 专题一：回归与因果1
### 周正卿
### 02 March 2022

---

class: center, middle, inverse



&lt;style type="text/css"&gt;
@media print {
  .has-continuation {
    display: block !important;
  }
}
&lt;/style&gt;


# 引言

---
name: schedule

# 课程进度

### 上节课

- 经验研究
- 条件期望函数CEF

### 今天 + 1或2

- CEF .mono[--&gt;] LPF .mono[--&gt;] 回归 .mono[--&gt;] 因果推断
&lt;br&gt;&lt;br&gt;
**.qa[重点阅读] ** *MHE* 3.1
---
layout: true

# 回归分析
---
class: inverse, middle
---
name: why

## 为什么使用回归？

回归研究结果变量 `\(Y\)` 与一系列原因变量 `\(X\)` 之间关系的众多方法。(C&amp;T, Ch4.1)

**.qa[Q]** 为什么经验研究者偏好使用线性回归和最小二乘方法 （LS）?

**.qa[A]**  使用回归分析可以帮助研究者：(1) 因果识别（causal identification） 和（2） 推断 （inference）。另外，系数估计的科学性（无偏、一致、有效）和计算可操作性的兼顾也是重要考虑。

常见的线性回归和OLS背后有共同基础: 条件期望函数（CEF）

---

## 为什么使用回归？


暂不考虑因果关系，理解回归分析的步骤:

- 深入理解CEF（条件期望函数）

- 总体回归函数（PRF by MHE）或者 线性投影函数(LPF by Hansen)

- 参数估计值的样本分布
---
layout: true

# 回归分析
## *CEF* 
---
name: cef
 
**.qa[上节课]:** 当涉及多个“条件”时，可以写作向量形式：

`$$E[ Y \mid X=x]=m(x)$$`
CEF `\(=m(x)=E[Y \mid X=x]\)` 是 `\(x \in \mathbb{R}^{k}\)`的函数 ，意味着“ 当 `\(X\)` 取值 `\(x\)` 时, `\(Y\)` 的平均值为 `\(m(x)\)` ”,由于 `\(X\)` 可以取值任意的 `\(x\)` , 因此将CEF视为随机变量 `\(X\)` 的函数, **CEF也是随机变量**。
 
 期望本身是总体概念，现实中面对的一个个样本，因而需要用样本信息推断总体信息（利用抽样分布与统计推断）,**i.e** 用样本均值推断总体期望。拿到样本，关心的其实是总体。
 
CEF是从**总体视角**出发，那么样本如何呈现？

---

 通过实验或者抽样得到N个观测点， CEF重新写作:
`\(E[Y_i \mid {X}_{i}]\)` 

- `\({X}_i\)` 是 `\(k \times 1\)` 的列向量，  `\({X}_{i}\)` 每个元素是 `\(x_{ki}\)`

- 若 `\(X_i\)` 是1维的， 比如 `\(X_i = 学历\)`，  `\(E[Y_i \mid {X}_{i} = 研究生]\)` ， 总体中所有“研究生学历”的 `\(Y\)` 的均值；若 `\(X_i\)` 是2维的， 比如 `\(X_i = \{学历,性别\}\)` ， `\(E[Y_i \mid {X}_{i} = \{本科,男性\}]\)` ，总体中所有“男性本科学历”的 `\(Y\)` 的均值

**.qa[Key]:  再次深刻理解条件期望函数是 `\(x\)` 的函数 **  

---
layout: false
class: clear, middle

从图形上看CEF...
---
class: clear, center, middle
name: graphically

条件分布 `\({Y}_{i}\)`,  对于8, ..., 22不同教育年限的 `\({X}_{i}=x\)`.



&lt;img src="02_Regression_and_causality1_files/figure-html/fig_cef_dist-1.svg" style="display: block; margin: auto;" /&gt;
---
class: clear, middle, center
条件期望函数, `\(\mathop{E}\left[ {Y}_{i}\mid {X}_{i} \right]\)` 其实是这些条件分布的均值

&lt;img src="02_Regression_and_causality1_files/figure-html/fig_cef-1.svg" style="display: block; margin: auto;" /&gt;

---
class: clear, middle, center

若只关注 CEF, `\(\mathop{E}\left[ {Y}_{i}\mid {X}_{i} \right]\)`...

&lt;img src="02_Regression_and_causality1_files/figure-html/fig_cef_only-1.svg" style="display: block; margin: auto;" /&gt;
---
## 实际数据（MHE）

.middle[
.center[
&lt;img src="figs/MHE-CEF.png" height="500"&gt;
]
]

---
layout: false

## 研究问题 .mono[--&gt;] .pink[CEF] 

CEF基于数据出发，对于理解变量间至关重要，但经验研究的第一问题是如何将理论结果转换为实证模型， `\({E}\left[ {工资}_i \mid {运动技能}_i \right]\)` :

- step 1：选取 `\(Y\)` 与 `\(X\)` (从研究问题出发)

- step 2：在总体中重复抽样，获得样本

- step 3：对 `\(X\)` "切片" ，获得 `\(Y \mid X=x\)` 的 条件密度和条件分布 

- step 4：制作联合密度表格  `\(P(Y=y , X=x)\)`

- step 5：计算边缘密度 `\(P(X=x)\)`

- step 6：制作条件密度表格 `\(P(Y \mid X=x) = \frac{P(Y=y , X=x)} {P(X=x)}\)`

- step 7：计算条件期望 `\(E(Y \mid X=x)\)` 
---
layout: true
# 回归分析
##  *CEF* 性质
---
name: decomposition

.hi.pink[分解清晰:] CEF 将观测的结果变量分解成两部分

$$
`\begin{align}
  {Y}_{i} = \color{#e64173}{\mathop{E}\left[ {Y}_{i}\mid {X}_{i} \right]} + \color{#6A5ACD}{e_i}
\end{align}`
$$

1. 被 `\(\color{#e64173}{{X}_{i}}\)` 解释的部分(_i.e._, CEF `\(\color{#e64173}{\mathop{E}\left[ {Y}_{i} \mid {X}_{i} \right]}\)`)
&lt;br&gt;
1. 具有特殊性质的误差项&lt;sup&gt;.pink[†]&lt;/sup&gt;
&lt;br&gt;&lt;br&gt; i.  `\(\color{#6A5ACD}{e_i}\)` 均值独立于  `\({X}_{i}\)`, _i.e._, `\(\mathop{E}\left[ \color{#6A5ACD}{e_i} \mid {X}_{i} \right] = 0\)`
&lt;br&gt; ii.  `\(\color{#6A5ACD}{e_i}\)` 与 `\({X}_{i}\)`的任何函数不相干


.footnote[.pink[†] 回忆第一讲的性质.]

---

.hi.pink[ANOVA 定理:]

无条件方差与条件方差的关系：可将结果变量 `\(Y_i\)` 方差分解为两部分

$$
`\begin{align}
  \mathop{{Var}} \left( {Y}_{i} \right) =  \mathop{E}\left[ \mathop{{Var}} \left( {Y}_{i} \mid {X}_{i} \right) \right]+ \mathop{{Var}} \left( \color{#e64173}{\mathop{E}\left[ {Y}_{i} \mid {X}_{i} \right]} \right) 
\end{align}`
$$
 
1. 组内方差(的均值)(within group variance)。每个"等级"内Y的分布的方差的期望值(均值)。

2. 组间方差(across group variance)。条件期望值在"等级"间的分布的方差

或者MHE将上式分解为：CEF的方差(CEF可以解释) .mono[+] 干扰项的方差(CEF无法可以解释)

---
name: prediction

.hi.pink[良好预测:]  `\(\mathop{m}\left( {X}_{i} \right)\)` 为 `\({X}_{i}\)` 任意形式函数, CEF是最小均方误差（**性质5**）
$$
`\begin{align}
  \color{#e64173}{\mathop{E}\left[ {Y}_{i} \mid {X}_{i} \right]} = \underset{\mathop{m}\left( {X}_{i} \right)}{{arg min}}\enspace \mathop{E}\left[ \left( {Y}_{i} - \mathop{m}\left( {X}_{i} \right) \right)^2 \right]
\end{align}`
$$
CEF是给定 `\({X}_{i}\)` 能够预测 `\({Y}_{i}\)` 最好预测方式.


.qa[*注意*]
 `\(m\)` 可以是任意形式函数（包含非线性）.

---
layout: false

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
但问题是：CEF的函数形式非常复杂，有没有既形式简单，又良好预测，且分解清晰的办法呢？
&lt;br&gt;
--
&lt;br&gt;
答案是：**LPF** 线性投影函数
&lt;br&gt;
--
&lt;br&gt;
.hi.pink[深度阅读：] 为什么不是线性CEF，而是LPF呢? 线性CEF(linear CEF model)也就是常见的线性回归模型(linear regression model)。其中一个原因是 `\(m(x1,x2)\)` 其完整的线性形式写作 `\(m\left(x_{1}, x_{2}\right)=x_{1} \beta_{1}+x_{2} \beta_{2}+x_{1}^{2} \beta_{3}+x_{2}^{2} \beta_{4}+x_{1} x_{2} \beta_{5}+\beta_{6}\)`  .mono[--&gt;] 《E》，30-38
&lt;br&gt;
---
layout: false
class: clear, middle

线性回归是实证分析中应用最广泛的一种方法。

- LPF 与 CEF 什么关系？

- 什么条件下 LPF 具有因果解释？

---
layout: true
# 回归分析
##  CEF 与 LPF
---
name: pop_ls

CEF是具有好的预测性质，那么“好”**准则**是什么？

定义**损失函数(loss function)**,  表达为常用的二次型形式：

$$ L(Y, g(x))=(Y-g(x))^{2} $$
其中 `\(L(·)\)` 是r.v.，取期望得**均值平方误差（mean squared error，MSE）**，简称**均方误**
$$ R(Y, g(x)) = E[L(Y, g(x))] = E[(Y-g(x))^{2}] $$

.hi.slate[回忆：]CEF是MMSE(**性质5**)

---
name: pop_ls

### *LPF*
 
 寻找使得MSE最小化的线性函数:

$$
`\begin{align}
  \beta = \underset{b}{{arg min}}\thinspace \mathop{E}\left[ \left( {Y}_{i} - {X}_{i}'b \right)^2 \right]
\end{align}`
$$
其中 `\(b\)` 与 `\({X}_{i}\)` 都是 `\(K\times 1\)` 向量,  `\({Y}_{i}\)` 是标量, `\(\beta\)` 是 `\(K\times 1\)` 向量, 是通过最小化MSE得到估计系数（也就是之后讲的OLS）。

依据一阶条件: `\(\mathop{E}\left[ {X}_{i} \left( {Y}_{i} - {X}_{i}'b \right) \right] = 0\)`得到 `\(b\)` 的最优解 `\(\beta = \mathop{E}\left[ {X}_{i} {X}_{i}' \right]^{-1} \mathop{E}\left[ {X}_{i} {Y}_{i} \right]\)`
---

### *LPF*

`\(X_{i}^{\prime} \beta\)` 是 `\(Y_i\)` 在 `\(X_i\)` 上的最优线性投影（best linear projection, BLP，MHE 3.1.5）, 向量 `\(\beta\)` 是线性投影系数（linear projection coefficient） 

根据一阶条件重新构建 `\(E\left[X_{i}\left(Y_{i}-X_{i}^{\prime} \beta\right)\right]=0\)` , 也就是说 `\(Y\)` 的线性投影函数误差(linear projection function error,LPFE )
`\(e_i = Y_i - X_{i}^{\prime} \beta\)` 与 `\(X_i\)` 不相关, 也就是说LPF具有
`\(E(X_i e_i) = 0\)` (矩阵形式为 `\(E[Xe]=0\)` )
的性质.

- .hi.pink[思考：]与CEFE的性质比较

---

### *CEF*与*LPF* 

LPF是MMSE，CEF是MMSE。两者什么关系? 继续使用最小化MSE**准则**：
$$
`\begin{align}
  \beta = \underset{b}{{arg min}}\thinspace \mathop{E}\left[ \left( m({X_i})-{X_i}^{\prime} b \right)^2 \right]
\end{align}`
$$

回归与条件期望函数定理（ Regression-CEF Theorem, MHE 3.1.6），结论：
&lt;br&gt;
- **LPF就是CEF的MMSE**, 是CEF的BLP（ MHE 3.1.6 的含义）
- 通常CEF不是LPF, 但若CEF是线性的, 那么 LPF .mono[==] CEF（ MHE 3.1.4）

---
layout: false
class: clear, middle, center

**CEF**

&lt;img src="02_Regression_and_causality1_files/figure-html/fig_reg_cef-1.svg" style="display: block; margin: auto;" /&gt;
---
class: clear, center, middle

LPF

&lt;img src="02_Regression_and_causality1_files/figure-html/fig_reg_cef2-1.svg" style="display: block; margin: auto;" /&gt;
---

## 实际数据（MHE）

.middle[
.center[
&lt;img src=https://pkuzzq-image.oss-cn-beijing.aliyuncs.com/uPic/RgBq9Q.png height="500"&gt;
]
]

&lt;!-- --- --&gt;
&lt;!-- layout: true --&gt;

&lt;!-- # 回归分析 --&gt;
&lt;!-- ##  CEF 与 LPF --&gt;
&lt;!-- --- --&gt;
&lt;!-- name: wls --&gt;

&lt;!-- 回归-CEF定理(MHE 3.1.6)意味着可以使用 `\(E [Y_i|X_i]\)` 作为观测点 `\(Y_i\)` 的替代值 --&gt;

&lt;!--  以 `\({X}_{i}\)` 是离散变量为例，其边缘密度函数为 `\(\mathop{g_x}(u)\)` --&gt;
&lt;!-- $$ --&gt;
&lt;!-- \begin{align} --&gt;
&lt;!--   \mathop{E}\!\bigg[ \left( \color{#e64173}{\mathop{E}\left[ {Y}_{i} \mid {X}_{i} \right]} - {X}_{i}'b \right)^2 \bigg] = \sum_u \left( \mathop{E}\left[ {Y}_{i} \mid {X}_{i} = u \right] - u'b \right)^2 \mathop{g_x}(u) --&gt;
&lt;!-- \end{align} --&gt;
&lt;!-- $$ --&gt;

&lt;!-- 利用一阶条件可得： --&gt;
&lt;!-- `\(\beta\)` --&gt;
&lt;!-- `\(= \mathop{E}\left[ X_i X_i' \right]^{-1} \mathop{E}\left[ {X}_{i}{Y}_{i} \right]\)` --&gt;
&lt;!-- `\(= \mathop{E}\left[ X_i X_i' \right]^{-1} \mathop{E}\left[ {X}_{i} \mathop{E}\left( {Y}_{i}\mid {X}_{i} \right) \right]\)`  --&gt;

&lt;!-- --- --&gt;

&lt;!-- ### 加权最小二乘的理解 --&gt;

&lt;!-- `\(\beta\)` 可以看做是 `\(\mathop{E}\left[ {Y}_{i} \mid {X}_{i} = u\right]\)` 关于 `\(X_i = u\)` 处进行加权最小二乘(WLS)对 `\(X_i\)` 回归，其中 `\(u\)` 取遍了所有 `\(X_i\)` 的取值。 --&gt;

&lt;!-- 加权的好处是： 当从事研究项目无法使用微观数据获得 `\(Y_i\)`，就可以使用条件期望函数或者分组（加总）数据进行回归。 --&gt;

&lt;!-- 不好处是：会与OLS得到不同的标准差 --&gt;



&lt;!-- --- --&gt;
&lt;!-- layout: false --&gt;
&lt;!-- class: clear, middle --&gt;

&lt;!-- 用2002年中国居民收入调査（CHIP)城镇数据获得以下回归。A部分是 --&gt;
&lt;!-- 用个体回归，9581个样本点，得到的教育收益率为0,0715。B部分是用教育年限分组估计，教育年限为0—23年24个。利用各层次教育个体数量作为权重进行加权最小二乘估计，得到的教育收益率也是0.0715,当然标准误差不同。（by 《基本有用的计量经济学》） --&gt;

&lt;!-- .middle[ --&gt;
&lt;!-- .center[ --&gt;
&lt;!-- &lt;img src=https://pkuzzq-image.oss-cn-beijing.aliyuncs.com/uPic/HcE1rE.png height="460"&gt; --&gt;
&lt;!-- ] --&gt;
&lt;!-- ] --&gt;
---
## LPF的参数识别

.more-left[
&lt;img src=https://pkuzzq-image.oss-cn-beijing.aliyuncs.com/uPic/XZ0XRC.png height="330" /img&gt;
]

.less-right[
`\(\beta = \mathop{E}\left[ {X}_{i} {X}_{i}' \right]^{-1} \mathop{E}\left[ {X}_{i} {Y}_{i} \right]\)` 在实际观测点中怎样获得? 涉及到 `\(\beta\)`  的识别问题（唯一且可估计）

Hansen ：保证 `\(k \times k\)` 的 **设计矩阵（design matrix）** `\(\boldsymbol{Q}_{X X}= {E}\left[X X^{\prime}\right]\)` 是可逆的，就可以识别LPF参数 `\(\beta\)` 。
]

---
# 回归分析
## CEF与LPF系数含义的区别

- 线性CEF的参数

.pull.right[
$$
{E}[\log ( { wage }) \mid  { Black, female }]=-0.20  { Black }-0.24  { female }+0.10  { Black } \times  { female }+3.06
$$
]

  ```
    线性CEF: 黑人男性（相对于非黑人的男性）低20%，黑人女性（相对于非黑人女性）为高10%。
  ```

- LPF的参数
.pull.right[
$$
\mathscr{P} [ \log ( { wage }) \mid  { Black, female } ]=-0.15  { Black }-0.23  { female }+3.06
$$
]

  ```      
  LPF: 黑人打工者（相对于非黑人)低15%，忽略了性别的作用(计算净影响)，控制变量保证条件相同。
  ```
    
---
# 回归分析
## CEF、LPF和因果关系

.hi-pink[考虑到：] LPF 是 CEF 的MMSE， 是 CEF 的 BLP

若CEF是相关关系的 .mono[--&gt;] LPF是相关的
&lt;br&gt;
--
&lt;br&gt;
若CEF是因果关系 .mono[--&gt;] LPF是因果的
&lt;br&gt;
--
&lt;br&gt;
问题是：怎样获得一个因果的 CEF ？(客观)
&lt;br&gt;
--
&lt;p&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
.mono[--&gt;]  必须依赖于理论认知(主观) 
&lt;/p&gt;
  

---
# 回归分析
## CEF、LPF和因果关系

.hi-pink[实际上]，我们是从理论得到结论，进而在样本中验证理论关系是否成立。因此，直接作法是使用 LPF 进行建模。 

由于只有 **线性的CEF .mono[==] LPF**，使用 LPF建模(即便模型设定是正确的)      
**先天的** 一部分信息就进入到了干扰项 `\(e\)` ，因此只有假定 **干扰项条件均值独立于解释变量** ，即  `\(E(e \mid X) = E(e)=c\)` ，才保证 LPF（依据理论建构的模型）= CEF（线性） 

.hi-pink[回忆下：] CEFE 天然就具备性质  `\(E(e \mid X) = E(e)=0\)` 

---
## 干扰项条件均值独立于解释变量的理解
.pull-left[

假设 LPF： `\(INC = \alpha + \beta_1 EDU + \beta_2 IQ + e\)`  


&lt;img src=https://pkuzzq-image.oss-cn-beijing.aliyuncs.com/uPic/drGBU8.png &gt;
]

.pull-right[
- 有向无环图(directed acyclic graph)
- 实心-可观测；空心-不可观测；单向箭头-因果关系；无法递归
- EDU .mono[-&gt;] INC 直接因果路径
- EDU .mono[&lt;-] IQ .mono[-&gt;] INC 混淆路径1
- EDU .mono[&lt;-] e  .mono[-&gt;] INC 混淆路径2
- 右图：干扰项条件均值独立于解释变量
- 左图：控制IQ无效
]
---
## 干扰项条件均值独立于解释变量的理解

 `\(E(e \mid EDU, IQ) = E(e)=c\)` 意味着：给定我们班{EDU = 研究生, IQ = 高} 干扰项的平均值一样(c)，假如性格（不可观测）进入 e，干扰项条件均值独立于解释变量成立就表示符合上面两个条件的同学的性格是一样的。
 
这样，若EDU与IQ其中一个变化，另一不变，收入的条件平均值变化就可以归因于其中那个变化了的条件，获得“净”的因果效应。

因此，LPF中的参数 `\(\beta_1\)` 和 `\(\beta_2\)` 就是 EDU 和 IQ 对 INC 的因果效应。

将 `\(E(e \mid EDU, IQ) =c\)` 的常数c 并入 LPF常数项，就获得了与CEFE性质一样的 
`\(E(e \mid EDU, IQ) =0\)` 重要假设。 只不过该假设是从 LPF 出发建立的，也就是常在计量教材见到的线性回归方程的**干扰项条件均值为0**的假设。

---
## 干扰项条件均值独立于解释变量的理解

对LPF： `\(INC = \alpha + \beta_1 EDU + \beta_2 IQ + e\)`  

两边取条件期望, 得到对应的线性CEF:
$$
`\begin{aligned}
&amp;{E}(I N C \mid E D U, I Q) \\
&amp;=\alpha+\beta_{1} E D U+\beta_{2} I Q+{E}(e \mid E D U, I Q) \\
&amp;=\alpha+\beta_{1} E D U+\beta_{2} I Q
\end{aligned}`
$$
将线性CEF对EDU求偏导：偏回归系数
$$
\frac{d {E}(INC \mid EDU, IQ)}{d EDU}=\beta_{1}
$$

`\(\beta_{1}\)` 表示在IQ固定不变，INC 的期望值（均值）随 EDU 如何变化。 
---
## 相关关系CEF

若 `\(E(e \mid EDU, IQ) \neq 0\)` , 干扰项的存在如何影响因果关系的估计?

假设只观测到了INC和EDU, 将 LPF 写作：

`$$I N C=\alpha+\beta_{1} E D U+\varepsilon, \quad \varepsilon=\beta_{2} I Q+e$$`
此时:

`$${E}(\varepsilon \mid E D U)={E}(\beta_{2} I Q+{e} \mid EDU)=\beta_{2}{E}(IQ \mid EDU) \neq 0$$`

此时的LPF为:

$$
I N C=\alpha+\beta_{1} E D U+\varepsilon,\quad {E}(\varepsilon \mid E D U) \neq 0
$$

---
## 相关关系CEF

假如此时我们错误地把 LPF 当成了 正确的、具有因果关系的线性CEF，

实际上相当于理解为 我们建构的模型 LPF.super[*]： `\(I N C=\gamma_{0}+\gamma_{1} E D U+u, \quad {E}(u \mid E D U=0)\)` 

的对应的"具有因果关系"（其实是相关关系）CEF.super[*]： `\(E(I N C \mid E D U)=\gamma_{0}+\gamma_{1} E D U\)` 

求偏导：
$$ \frac{d {E}(I N C \mid E D U)}{d E D U}=\gamma_{1}$$

 `\(\gamma_{1}\)` 反映了INC 的期望值随EDU如何变化, 但并没有控制IQ不变。
---
## 相关关系CEF

计算 `\(\gamma_{1}\)` 和 `\(\beta_{1}\)` 的关系:
$$
`\begin{aligned}
&amp;{E}(I N C \mid E D U) \\
&amp;={E}\left(\alpha+\beta_{1} E D U+\beta_{2} I Q+{e} \mid E D U\right) \\
&amp;=\alpha+\beta_{1} E D U+\beta_{2} {E}(I Q \mid E D U)
\end{aligned}`
$$
- 对EDU求导:
`$$\frac{d {E}(I N C \mid E D U)}{d E D U}=\beta_{1}+\beta_{2} \frac{d {E}(I Q \mid E D U)}{d E D U}$$`
即 
`$$\gamma_{1}=\beta_{1}+\beta_{2} \frac{d {E}(I Q \mid E D U)}{d E D U}$$`
---
## 相关关系CEF

- 假设受教育程度于智商之间存在线性相关关系: 
`$${E}(I Q \mid E D U)=\phi_{0}+\phi_{1} E D U$$`
即
`$$\frac{d {E}(I Q \mid E D U)}{d E D U}=\phi_{1}$$`
则：
`$$\gamma_{1}=\beta_{1}+\beta_{2} \phi_{1}$$` 

---
## 相关关系CEF

由此可见，错误的LPF.super[*]: `\(I N C=\gamma_{0}+\gamma_{1} E D U+u, \quad {E}(u \mid E D U=0)\)` 

--

代表是错误的线性CEF.super[*] ，其估计系数 `\(\gamma_1\)` 反映是相关关系:

- EDU .mono[-&gt;] INC 的因果影响 `\(\beta_1\)` 

- EDU 与 IQ 的 相关性 `\(\phi_1\)` 乘以 IQ 对 INC 的因果影响 `\(\beta_2\)` 
&lt;br&gt;
.center[
&lt;img src=https://pkuzzq-image.oss-cn-beijing.aliyuncs.com/uPic/cdFvLb.png height="250"&gt;
]

---
layout: true

# 统计推断与大样本性质

---
class: inverse, middle
---
name: ols

## 为什么需要推断?

**.qa[之前]** 重点关注了CEF与LPF，都是总体的。刻画总体我们只能通过样本, 通过统计推断的方式进行。

本小节要回答以下问题：

1. 如何估计系数 `\(\hat{\beta}\)` ?

2. `\(\hat{\beta}\)` 的样本分布如何?

3. 如何解释估计系数 `\(\hat{\beta}\)` ?

---
layout: false

 `\(\left[\begin{array}{c}Y_{1} \\ Y_{2} \\ \cdots \\ Y_{i} \\ \cdots \\ Y_{N}\end{array}\right]=\left[\begin{array}{ccccc}x_{11} &amp; x_{21} &amp; x_{31} &amp; \cdots &amp; x_{k 1} \\ x_{12} &amp; x_{22} &amp; x_{32} &amp; \cdots &amp; x_{k 2} \\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots \\ x_{1 i} &amp; x_{2 i} &amp; x_{3 i} &amp; \cdots &amp; x_{k i} \\ \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots \\ x_{1 N} &amp; x_{2 N} &amp; x_{3 N} &amp; \cdots &amp; x_{k N}\end{array}\right] \times\left[\begin{array}{c}\beta_{1} \\ \beta_{2} \\ \cdots \\ \beta_{i} \\ \cdots \\ \beta_{k}\end{array}\right]+\left[\begin{array}{c}e_{1} \\ e_{2} \\ \cdots \\ e_{i} \\ \cdots \\ e_{N}\end{array}\right]\)` 

进一步用 `\(k\)` 维向量 `\({X}_{i}=\left(\begin{array}{llllllll}x_{1 i} &amp; x_{2 i} &amp; \cdots &amp; x_{k i}\end{array}\right)^{\prime}, {\beta}=\left(\begin{array}{lllll}\beta_{1} &amp; \beta_{2} &amp; \cdots &amp; \beta_{k}\end{array}\right)^{\prime}\)` 简化为:

`\(\left[\begin{array}{c}Y_{1} \\ Y_{2} \\ \cdots \\ Y_{i} \\ \cdots \\ Y_{N}\end{array}\right]=\left[\begin{array}{c}{X}_{1}^{\prime} \\ {X}_{2}^{\prime} \\ \cdots \\ {X}_{i}^{\prime} \\ \cdots \\ {X}_{N}^{\prime}\end{array}\right] \times {\beta}+\left[\begin{array}{c}e_{1} \\ e_{2} \\ \cdots \\ e_{i} \\ \cdots \\ e_{N}\end{array}\right]\)`

再用 `\(N \times k\)` 矩阵 `\(\boldsymbol{X}=\left(\begin{array}{lll}{X}_{1} &amp; {X}_{2} &amp; \cdots {X}_{N}\end{array}\right)^{\prime}\)` 、 `\(N\)` 维向量 `\({Y}=\left(\begin{array}{llll}Y_{1} &amp; Y_{2} &amp; \cdots &amp; Y_{N}\end{array}\right)^{\prime}\)` `\(e=\left(\begin{array}{llll}e_{1} &amp; e_{2} &amp; \cdots &amp; e_{N}\end{array}\right)^{\prime}\)` 简化为:
$$
{Y}=\boldsymbol{X} {\beta}+e
$$

---
name: ols
## 总体最小二乘
 
将LPF 设定为: `\(Y=X^{\prime} \boldsymbol{\beta}+ e, \quad {E}(e \mid X)=0\)` 

展开: `\(Y=\alpha+\beta_{1} X_{1}+\cdots+\beta_{k} X_{k}+e\)`

该 LPF 对应的 线性CEF，可以是因果关系的CEF，也可以是相关关系的CEF:
$$
{E}(Y \mid X)=X^{\prime} \boldsymbol{\beta}
$$

利用最小二乘法求解系数 `\(\hat{\boldsymbol{\beta}}_{ols}\)` ，就是最小化 `\(Y\)` 与 线性投影预测值  `\(\hat{Y} = \boldsymbol{X}^{\prime} \boldsymbol{b}\)` 的残差 `\(\varepsilon = Y - \hat{Y}\)` 的MSE
$$
\hat{\boldsymbol{\beta}}_{ols}=\underset{b}{\operatorname{argmin}} {E}\left[\left(Y-\boldsymbol{X}^{\prime} \boldsymbol{b}\right)^{2}\right]
$$
---
name: ols
## 总体最小二乘

由一阶条件可得：
`$${E}\left[\boldsymbol{X}\left(Y-\boldsymbol{X}^{\prime} \hat{\boldsymbol{\beta}_{}}\right)\right]=0$$`
此条件同等与:
$$
{E}\left[\boldsymbol{X}\left(Y-\boldsymbol{X}^{\prime} \hat{\boldsymbol{\beta}}\right)\right]={E}[\boldsymbol{X} {\varepsilon}]=0
$$
由此可见, LS的本质是求解系数 `\(\hat{\boldsymbol{\beta}}_{ols}\)` ，使得解释变量 `\(X\)` 与残差 `\({\varepsilon}\)` 不相关
$$
\hat{\boldsymbol{\beta}}_{ols}={E}\left[\boldsymbol{X} \boldsymbol{X}^{\prime}\right]^{-1} {E}[\boldsymbol{X} Y]
$$
---
name: ols
## 总体最小二乘

将LPF代入上式:
$$
`\begin{aligned}
&amp;\hat{\boldsymbol{\beta}}_{ols}={E}\left[\boldsymbol{X} \boldsymbol{X}^{\prime}\right]^{-1} {E}[\boldsymbol{X} Y]={E}\left[\boldsymbol{X} \boldsymbol{X}^{\prime}\right]^{-1} {E}\left[\boldsymbol{X}\left(\boldsymbol{X}^{\prime} \boldsymbol{\beta}+e \right)\right] \\
&amp;=\boldsymbol{\beta}+{E}\left[\boldsymbol{X} \boldsymbol{X}^{\prime}\right]^{-1} {E}[\boldsymbol{X} e]
\end{aligned}`
$$
其中由于假设: `\({E}(e \mid X)=0\)`
- 故 `\({E}[\boldsymbol{X} e]={E}_{\boldsymbol{X}}[{E}(\boldsymbol{X} e \mid \boldsymbol{X})]={E}_{\boldsymbol{X}}[\boldsymbol{X} {E}(e \mid \boldsymbol{X})]=\mathbf{0}\)`
- 故 `\(\hat{\boldsymbol{\beta}}_{ols}=\boldsymbol{\beta}\)`
以上讨论说明, 最小二乘法的解对应的系数 `\(\hat{\boldsymbol{\beta}}_{ols}\)` 是LPF
`\(Y=\boldsymbol{X}^{\prime} \boldsymbol{\beta}+e, {E}(e \mid X)=0\)`, 即条件期望函数 `\({E}(Y \mid X)=\)` `\(\boldsymbol{X}^{\prime} \boldsymbol{\beta}\)` 的系数 `\(\boldsymbol{\beta}\)`

意味着： 对因果关系的CEF使用最小二乘方法 .mono[--&gt;] 估计的系数 `\(\hat{\boldsymbol{\beta}}_{ols}\)` 具有因果效应
---
## 干扰项和残差

- 干扰项 `\(e\)` 包含了除X外的其他影响Y的因素, 与X是否相关无法检验，靠经验和理论判断；

- 残差 `\(\varepsilon\)` 使用最小二乘法计算出来的, 总是与X不相关。
$$
{E}\left[\boldsymbol{X}\left(Y-\boldsymbol{X}^{\prime} \hat{\boldsymbol{\beta}}\right)\right]={E}[\boldsymbol{X} {\varepsilon}]=0
$$
- 只有当干扰项 `\(e\)` 与 X 不相关时, 残差 `\(\varepsilon\)` 才是干扰项 `\(e\)` 的正确估计。
---
name: ols
## 从总体到样本

最小二乘只是估计方法.super[.pink[†]]，常见的估计方法还有矩方法、最大似然估计等 

- 在总体中
`\(\hat{\boldsymbol{\beta}}_{ols}={E}\left[\boldsymbol{X} \boldsymbol{X}^{\prime}\right]^{-1} {E}[\boldsymbol{X} Y]\)` 
 
- 在样本中 `\(\hat{\boldsymbol{\beta}}_{ols}=\left(\sum_{i} X_{i} X_{i}^{\prime}\right)^{-1}\left(\sum_{i} X_{i} Y_{i}\right)\)`
 
.footnote[.pink[†]
**MHE** 还提供矩方法(method-of-moments) 作为备选。根据大数定律和 中心极限定理使用样本矩 `\(\dfrac{1}{n}\sum_i {X}_{i} {X}_{i}'\)` 估计总体矩 `\(\mathop{E}\left[{X}_{i} {X}_{i}' \right]\)`. 还可以使用其他估计方法, _e.g._ `\({Y}_{i}\)` 给定 `\({X}_{i}\)` 去最小化 `\({Y}_{i}\)` 的MSE.
]

---

假设真实的总体回归函数(永远未知)是 `\(Y=\boldsymbol{X}^{\prime} \boldsymbol{\beta}+e\)`,  代入上式可得: 
$$
`\begin{aligned}
\hat{\boldsymbol{\beta}}_{ols}=\boldsymbol{\beta}+{E}\left[\boldsymbol{X} \boldsymbol{X}^{\prime}\right]^{-1} {E}[\boldsymbol{X} e]
\end{aligned}`
$$
  
其渐进协方差为: `\({E}\left[ \boldsymbol{X} \boldsymbol{X}^{\prime} \right]^{-1} \boldsymbol{X}^{\prime}{E}\left[ ee^{\prime} \right] \boldsymbol{X}{E}\left[ \boldsymbol{X} \boldsymbol{X}^{\prime} \right]^{-1}\)` 

`$$\begin{aligned}
{E}\left[ ee^{\prime} \right]={Var}({e})=\boldsymbol{\Omega}= {\left[\begin{array}{ccccc}
\sigma_{1}^{2} &amp; \sigma_{12} &amp; \sigma_{13} &amp; \cdots &amp; \sigma_{1 N} \\
\sigma_{21} &amp; \sigma_{2}^{2} &amp; \sigma_{23} &amp; \cdots &amp; \sigma_{2 N} \\
\sigma_{31} &amp; \sigma_{32} &amp; \sigma_{3}^{2} &amp; \cdots &amp; \sigma_{3 N} \\
\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots \\
\sigma_{N 1} &amp; \sigma_{N 2} &amp; \sigma_{N 3} &amp; \cdots &amp; \sigma_{N}^{2}
\end{array}\right]}
\end{aligned}$$`

实际中用样本残差 `\(\varepsilon = Y - \hat{Y}\)` + 同方差/异方差假设 .mono[--&gt;] `\(Var(\hat \beta_{ols})\)`

---
## 几个重要的大样本性质
 
1. 统计推断建立在随机变量与样本分布基础上，实际就是用 `\(\hat{\beta}\)` 去推断真实值(未知) `\({\beta}\)`
1. `\(\hat{\beta}\)` 是一个r.v.,因此具有分布(均值和方差)
1. 在大样本下(n&gt;200),OLS估计量 `\(\hat{\beta}\)` 是总体回归系数 `\({\beta}\)` 的一致估计（ `\(\operatorname{plim} \hat{\beta}=\beta\)` ）
1. 用样本残差代入中间项得到标准误差称为异方差一致性标准误差或稳健标准误差,STATA中在回归后加上vce(robust)
1. 在传统计量经济学中，对推断问题的处理从更强的假设开始。传统方式有时候被叫做经典正态回归模型，它假定自变量是**固定随机变量**、CEF是线性的、总体误差项符合正态分布以及同方差。这些更强假设可以得到:（1）OLS估计量无偏性（小样本性质）,（2）OLS估计值的样本方差公式,在小样本和大样本中都成立,即有效的。这种情况下，即便CEF非线性，随机化实验(RCTs)也可保证无偏性.

---

因为异方差是社会科学的常态，所有Angrist and Pischke认为应该把很多统计工具的默认值切换到异方差(heteroskedasticity).

若是CEF是非线性的, 线性回归就会产生异方差.

`\(\mathop{E}\left[ \left( {Y}_{i} - {X}_{i}'\beta \right)^2 \mid {X}_{i} \right]\)`
&lt;br&gt;  `\(= \mathop{E} \left[ \bigg( \big\{ {Y}_{i} - \mathop{E}\left[ {Y}_{i} \mid {X}_{i} \right] \big\} + \big\{ \mathop{E}\left[ {Y}_{i} \mid {X}_{i} \right] - {X}_{i}'\beta \big\} \bigg)^2 \Bigg| {X}_{i} \right]\)`
&lt;br&gt;  `\(= \mathop{{Var}} \left( {Y}_{i} \mid {X}_{i} \right) + \left( \mathop{E}\left[ {Y}_{i} \mid {X}_{i} \right] - {X}_{i}'\beta \right)^2\)`

即使 `\(\mathop{{Var}} \left( {Y}_{i} \mid {X}_{i} \right)\)` 是常数, 第二项也是异方差.

---
name: ols
## 应用中

1. 异方差不是推断的.hi[最大障碍]. 
&gt; ...如果异方差变化很大，比如使标准误上升了30%或者有任何显著的下降，那么你应该注意是不是存在可能的程序错误或者是其他问题。如果稳健标准误低于传统意义上的标准误.super[.pink[†]](一般会大于)，可能标志着在稳健性计算中存在有限样本偏误。 (*MHE*, p.47)

2. 现代微观实证建立在大样本假定下，已经避免了强的经典假设(正态分布、自变量非随机、线性 CEF、同方差) .

.super[.pink[†]
标准差(SD)是样本数据的方差的平方根,衡量样本数据的离散程度; 标准误(SE)是样本均值(是r.v.)的标准差，衡量样本均值的离散程度。实际中用样本均值来推断总体均值，那么样本均值的离散程度（标准误）越大，抽样误差就越大。所以用标准误（SE）来衡量抽样误差的大小，所以统计软件中报告是SE
]

---
name: ols
## 韦恩图理解系数估计值

.more-left[
- 两两相交的部分指的是两个变量共同变化的部分，表明两个变量存在一定的线性相关关系 
- 
$$
`\begin{gathered}
INC=\alpha+\beta_{1} EDU+\beta_{2} IQ+e \\
{E}(e \mid E D U, I Q)=0 \\
Cov(EDU, IQ) \neq 0
\end{gathered}`
$$
-  `\(\beta_{1}\)` 反映的只有(2)的信息, `\(\beta_{2}\)` 反映的只有(4)的信息, 而信息(3)（反映了共同的影响）被同时舍去
- 此时, 回归系数反映了EDU和 `\({IQ}\)` 各自对INC的影响, 即因果关系
]
.less-right[
![iSBcmO](https://pkuzzq-image.oss-cn-beijing.aliyuncs.com/uPic/iSBcmO.png)
]
---
name: ols
## 系数估计值的分解

.more-left[
基于OLS得到任何 `\(X_{i}\)` 的系数 `\(\hat{\beta}_{{i}}\)` 都可以分解为两步求解

- 第一步: 将 `\(X_{i}\)` 作为因变量, 其他不包含 `\(X_{i}\)` 的解释变量 作为自变量,OLS得到残差项 `\(\widetilde{X}_{i}=\hat{v}_{i}\)` ,即(2)+(5)：
`$$X_{i}=\hat{\gamma}_{0}+\hat{\gamma}_{1} X_{1}+\cdots+\hat{\gamma}_{i-1} X_{i-1}+\hat{\gamma}_{i+1} X_{i+1}+\cdots+\hat{\gamma}_{k} X_{k}+\hat{v}_{i}$$`

- 第二步: Y作因变量, `\(\widetilde{X_{i}}\)` 作自变量, OLS得到 `\(\hat{\beta}_{{i}}\)` ,即(2): `$$Y=\hat{\alpha}+\hat{\beta}_{{i}} \widetilde{X}_{i}+\hat{\varepsilon}$$` 其中 
`\(\hat{\beta}_{{i}}=\frac{{Cov}\left(Y,\hat{v}_{i}\right)}{{Var}(\hat{v}_{i})}\)` 
]
 
.less-right[
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;img src=https://pkuzzq-image.oss-cn-beijing.aliyuncs.com/uPic/iSBcmO.png &gt;
]

---
exclude: true



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"ratio": "16:10.85"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
